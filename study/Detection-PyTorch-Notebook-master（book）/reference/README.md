[1] [Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[C]// NIPS. Curran Associates Inc. 2012](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

[2] [Mcculloch W S , Pitts W . A Logical Calculus of the Ideas Immanent in Nervous Activity[J]. Bulletin of Mathematical Biology, 1943, 52(1–2):99-115.](https://link.springer.com/article/10.1007%2FBF02478259)

[3] [Lecun Y , Bottou L , Bengio Y , et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11):2278-2324.](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)

[4] [Hinton G E , Osindero S , Teh Y W . A Fast Learning Algorithm for Deep Belief Nets[J]. Neural Computation, 2006, 18(7):1527-1554.](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)

[5] [Glorot X, Bordes A, Bengio Y. Deep sparse rectifier neural networks[C]//Proceedings of the fourteenth international conference on artificial intelligence and statistics. 2011: 315-323.](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)

[6] [Wang P, Chen P, Yuan Y, et al. Understanding convolution for semantic segmentation[C]//2018 IEEE winter conference on applications of computer vision (WACV). IEEE, 2018: 1451-1460.](https://arxiv.org/pdf/1702.08502.pdf)

[7] [Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.](https://arxiv.org/pdf/1409.1556.pdf)

[8] [Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 1-9.](https://arxiv.org/pdf/1409.4842.pdf)

[9] [Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift[J]. arXiv preprint arXiv:1502.03167, 2015.](https://arxiv.org/pdf/1502.03167.pdf)

[10] [Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the inception architecture for computer vision[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 2818-2826.](https://arxiv.org/pdf/1512.00567.pdf)

[11] [Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3431-3440.](https://arxiv.org/pdf/1602.07261.pdf)

[12] [He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.](https://arxiv.org/pdf/1512.03385.pdf)

[13] [Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.](https://arxiv.org/pdf/1608.06993.pdf)

[14] [Lin T Y, Dollár P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2117-2125.](https://arxiv.org/pdf/1612.03144.pdf)

[15] [Li Z, Peng C, Yu G, et al. Detnet: A backbone network for object detection[J]. arXiv preprint arXiv:1804.06215, 2018.](https://arxiv.org/pdf/1804.06215.pdf)

[16] [Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.](https://arxiv.org/pdf/1311.2524.pdf)

[17] [He K, Zhang X, Ren S, et al. Spatial pyramid pooling in deep convolutional networks for visual recognition[J]. IEEE transactions on pattern analysis and machine intelligence, 2015, 37(9): 1904-1916.](https://arxiv.org/pdf/1406.4729.pdf)

[18] [Girshick R. Fast r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2015: 1440-1448.](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)

 [19] [Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.](https://arxiv.org/pdf/1506.01497.pdf)

[20] [Kong T, Yao A, Chen Y, et al. Hypernet: Towards accurate region proposal generation and joint object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 845-853.](https://arxiv.org/pdf/1604.00600.pdf)

[21] [He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2961-2969.](https://arxiv.org/pdf/1703.06870.pdf)

[22] [Dai J, Li Y, He K, et al. R-fcn: Object detection via region-based fully convolutional networks[C]//Advances in neural information processing systems. 2016: 379-387.](https://arxiv.org/pdf/1605.06409.pdf)

[23] [Cai Z, Vasconcelos N. Cascade r-cnn: Delving into high quality object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 6154-6162.](https://arxiv.org/pdf/1712.00726.pdf)

[24] [Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]//European conference on computer vision. Springer, Cham, 2016: 21-37.](https://arxiv.org/pdf/1512.02325.pdf)

[25] [Fu C Y, Liu W, Ranga A, et al. Dssd: Deconvolutional single shot detector[J]. arXiv preprint arXiv:1701.06659, 2017.](https://arxiv.org/pdf/1701.06659.pdf)

[26] [Jeong J, Park H, Kwak N. Enhancement of SSD by concatenating feature maps for object detection[J]. arXiv preprint arXiv:1705.09587, 2017.](https://arxiv.org/pdf/1705.09587.pdf)

[27] [Zhang S, Wen L, Bian X, et al. Single-shot refinement neural network for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 4203-4212.](https://arxiv.org/pdf/1711.06897.pdf)

[28] [Liu S, Huang D. Receptive field block net for accurate and fast object detection[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 385-400.](https://arxiv.org/pdf/1711.07767.pdf)

[29] [Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.](https://arxiv.org/pdf/1506.02640.pdf)

[30] [Redmon J, Farhadi A. YOLO9000: better, faster, stronger[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 7263-7271.](https://arxiv.org/pdf/1612.08242.pdf)

[31] [Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018.](https://arxiv.org/pdf/1804.02767.pdf)

[32] [Iandola F N, Han S, Moskewicz M W, et al. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size[J]. arXiv preprint arXiv:1602.07360, 2016.](https://arxiv.org/pdf/1602.07360.pdf)

[33] [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)

[34] [Sandler M, Howard A, Zhu M, et al. Mobilenetv2: Inverted residuals and linear bottlenecks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 4510-4520.](https://arxiv.org/pdf/1801.04381.pdf)

[35] [Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 6848-6856.](https://arxiv.org/pdf/1707.01083.pdf)

[36] [Ma N, Zhang X, Zheng H T, et al. Shufflenet v2: Practical guidelines for efficient cnn architecture design[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 116-131.](https://arxiv.org/pdf/1807.11164.pdf)

[37] [Bodla N, Singh B, Chellappa R, et al. Soft-NMS--Improving Object Detection With One Line of Code[C]//Proceedings of the IEEE international conference on computer vision. 2017: 5561-5569.](https://arxiv.org/pdf/1704.04503.pdf)

[38] [He Y, Zhang X, Savvides M, et al. Softer-nms: Rethinking bounding box regression for accurate object detection[J]. arXiv preprint arXiv:1809.08545, 2018.](https://arxiv.org/pdf/1809.08545v1.pdf)

[39] [Jiang B, Luo R, Mao J, et al. Acquisition of localization confidence for accurate object detection[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 784-799.](https://arxiv.org/pdf/1807.11590.pdf)

[40] [Shrivastava A, Gupta A, Girshick R. Training region-based object detectors with online hard example mining[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 761-769.](https://arxiv.org/pdf/1604.03540.pdf)

[41] [Lin T Y, Goyal P, Girshick R, et al. Focal loss for dense object detection[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2980-2988.](https://arxiv.org/pdf/1708.02002.pdf)

[42] [Singh B, Davis L S. An analysis of scale invariance in object detection snip[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3578-3587.](https://arxiv.org/pdf/1711.08189v1.pdf)

[43] [Li Y, Chen Y, Wang N, et al. Scale-aware trident networks for object detection[J]. arXiv preprint arXiv:1901.01892, 2019.](https://arxiv.org/pdf/1901.01892.pdf)

[44] [Wang X, Xiao T, Jiang Y, et al. Repulsion loss: Detecting pedestrians in a crowd[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7774-7783.](https://arxiv.org/pdf/1711.07752.pdf)

[45] [Zhang S, Wen L, Bian X, et al. Occlusion-aware R-CNN: detecting pedestrians in a crowd[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 637-653.](https://arxiv.org/pdf/1807.08407.pdf)

[46] [Qin Z, Li Z, Zhang Z, et al. Thundernet: Towards real-time generic object detection[J]. arXiv preprint arXiv:1903.11752, 2019.](https://arxiv.org/pdf/1903.11752.pdf)

[47] [Rosenfeld A, Zemel R, Tsotsos J K. The elephant in the room[J]. arXiv preprint arXiv:1808.03305, 2018.](https://arxiv.org/pdf/1808.03305.pdf)

[48] [Hu H, Gu J, Zhang Z, et al. Relation networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3588-3597.](https://arxiv.org/pdf/1711.11575.pdf)

[49] [Chen Y, Fang H, Xu B, et al. Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution[J]. arXiv preprint arXiv:1904.05049, 2019.](https://arxiv.org/pdf/1904.05049.pdf)

[50] [Zoph B, Vasudevan V, Shlens J, et al. Learning transferable architectures for scalable image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 8697-8710.](https://arxiv.org/pdf/1707.07012.pdf)

[51] [Zhong Z, Yan J, Wu W, et al. Practical block-wise neural network architecture generation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 2423-2432.](https://arxiv.org/pdf/1708.05552.pdf)

[52] [Chen Y, Yang T, Zhang X, et al. Detnas: Neural architecture search on object detection[J]. arXiv preprint arXiv:1903.10979, 2019.](https://arxiv.org/pdf/1903.10979.pdf)

[53] [Law H, Deng J. Cornernet: Detecting objects as paired keypoints[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 734-750.](https://arxiv.org/pdf/1808.01244.pdf)

[54] [Zhou X, Wang D, Krähenbühl P. Objects as Points[J]. arXiv preprint arXiv:1904.07850, 2019.](https://arxiv.org/pdf/1904.07850.pdf)

[55] [Wang J, Chen K, Yang S, et al. Region proposal by guided anchoring[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019: 2965-2974.](https://arxiv.org/pdf/1901.03278.pdf)

